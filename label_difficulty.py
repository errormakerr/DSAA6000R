import json
import sys
import os
import traceback

# æ·»åŠ  spider-master ç›®å½•åˆ°æœç´¢è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
spider_dir = os.path.join(current_dir, 'spider-master')

if spider_dir not in sys.path:
    sys.path.insert(0, spider_dir)

print(f"ğŸ“ å½“å‰ç›®å½•: {current_dir}")
print(f"ğŸ“ Spiderç›®å½•: {spider_dir}")

# å¯¼å…¥æ‰€éœ€æ¨¡å—
try:
    from process_sql import get_schema, Schema, get_sql
    from evaluation import Evaluator
    print("âœ… æ¨¡å—å¯¼å…¥æˆåŠŸ\n")
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    sys.exit(1)

def convert_tables_json_to_schema(table_data):
    """å°†tables.jsonæ ¼å¼è½¬æ¢ä¸ºSchemaæœŸæœ›çš„æ ¼å¼ï¼ˆç»Ÿä¸€å°å†™ï¼‰"""
    schema = {}
    
    # è·å–è¡¨åï¼ˆè½¬å°å†™ï¼‰
    table_names = [t.lower() for t in table_data['table_names_original']]
    
    # éå†æ¯ä¸ªè¡¨ï¼Œæ„å»º schema
    for table_idx, table_name in enumerate(table_names):
        # è·å–è¯¥è¡¨çš„æ‰€æœ‰åˆ—ï¼ˆè½¬å°å†™ï¼‰
        columns = []
        for col_idx, (tbl_idx, col_name) in enumerate(table_data['column_names_original']):
            if tbl_idx == table_idx:
                # ğŸ”§ å…³é”®ï¼šå°†åˆ—åè½¬ä¸ºå°å†™
                columns.append(col_name.lower())
        
        schema[table_name] = columns
    
    return schema

def label_difficulty(gold_file, db_dir, tables_file, output_file):
    """ä¸ºgold SQLæ ‡æ³¨éš¾åº¦"""
    
    # åˆå§‹åŒ–evaluator
    evaluator = Evaluator()
    
    # è¯»å–goldæ–‡ä»¶
    with open(gold_file, 'r', encoding='utf-8') as f:
        gold_lines = f.readlines()
    
    # è¯»å–tablesä¿¡æ¯
    with open(tables_file, 'r', encoding='utf-8') as f:
        tables_data = json.load(f)
    
    # æ„å»ºæ•°æ®åº“ååˆ°schemaçš„æ˜ å°„
    db_schemas = {}
    for table in tables_data:
        db_id = table['db_id']
        # ğŸ”§ è½¬æ¢æ ¼å¼ï¼ˆç»Ÿä¸€å°å†™ï¼‰
        schema_dict = convert_tables_json_to_schema(table)
        db_schemas[db_id] = schema_dict
    
    print(f"ğŸ“Š å·²åŠ è½½ {len(db_schemas)} ä¸ªæ•°æ®åº“çš„schema")
    
    # ğŸ” è°ƒè¯•ï¼šæ‰“å°ç¬¬ä¸€ä¸ªschemaçš„ç»“æ„
    if db_schemas:
        first_db = list(db_schemas.keys())[0]
        print(f"\nğŸ” ç¤ºä¾‹æ•°æ®åº“ '{first_db}' çš„schema:")
        for table, cols in list(db_schemas[first_db].items())[:2]:
            print(f"   {table}: {cols[:3]}...")
    print()
    
    results = []
    success_count = 0
    error_count = 0
    schema_cache = {}  # ç¼“å­˜å·²åˆ›å»ºçš„Schemaå¯¹è±¡
    
    for idx, line in enumerate(gold_lines):
        parts = line.strip().split('\t')
        if len(parts) < 2:
            continue
        
        sql_str = parts[0].strip()
        db_name = parts[1].strip()
        
        if not sql_str or not db_name:
            continue
        
        try:
            # è·å–æˆ–åˆ›å»ºSchemaå¯¹è±¡
            if db_name not in schema_cache:
                if db_name in db_schemas:
                    # ä½¿ç”¨tables.jsonä¸­çš„schema
                    schema_cache[db_name] = Schema(db_schemas[db_name])
                else:
                    # ä»æ•°æ®åº“æ–‡ä»¶è¯»å–
                    db_path = os.path.join(db_dir, db_name, f"{db_name}.sqlite")
                    if not os.path.exists(db_path):
                        raise FileNotFoundError(f"Database not found: {db_path}")
                    schema_dict = get_schema(db_path)
                    schema_cache[db_name] = Schema(schema_dict)
            
            schema = schema_cache[db_name]
            
            # è§£æSQL
            sql = get_sql(schema, sql_str)
            
            # è®¡ç®—éš¾åº¦
            hardness = evaluator.eval_hardness(sql)
            
            # ä¿å­˜ç»“æœ
            results.append({
                'index': idx,
                'database': db_name,
                'sql': sql_str,
                'difficulty': hardness
            })
            
            success_count += 1
            
            # æ¯100æ¡æ‰“å°ä¸€æ¬¡è¿›åº¦
            if (idx + 1) % 100 == 0:
                print(f"âœ… [{idx+1}/{len(gold_lines)}] æˆåŠŸ: {success_count}, å¤±è´¥: {error_count}")
            
        except Exception as e:
            error_count += 1
            
            # è¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼ˆå‰5ä¸ªé”™è¯¯ï¼‰
            if error_count <= 5:
                print(f"\nâŒ [{idx+1}] é”™è¯¯è¯¦æƒ…:")
                print(f"   æ•°æ®åº“: {db_name}")
                print(f"   SQL: {sql_str[:100]}...")
                print(f"   é”™è¯¯: {e}")
                
                # ğŸ” æ‰“å°è¯¥æ•°æ®åº“çš„schemaï¼ˆå¸®åŠ©è°ƒè¯•ï¼‰
                if db_name in db_schemas:
                    print(f"   Schema keys: {list(db_schemas[db_name].keys())}")
                    for table, cols in list(db_schemas[db_name].items())[:1]:
                        print(f"   {table} çš„åˆ—: {cols[:5]}...")
                
                if error_count <= 3:
                    print(f"   å®Œæ•´å †æ ˆ:")
                    traceback.print_exc()
                print()
            elif error_count == 6:
                print(f"âš ï¸  åç»­é”™è¯¯å°†åªæ˜¾ç¤ºç®€è¦ä¿¡æ¯...\n")
            else:
                if error_count % 100 == 0:
                    print(f"âš ï¸  å·²å¤„ç† {idx+1} æ¡ï¼Œå¤±è´¥ {error_count} æ¡")
            
            results.append({
                'index': idx,
                'database': db_name,
                'sql': sql_str,
                'difficulty': 'error',
                'error': str(e)
            })
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    # ç»Ÿè®¡
    stats = {}
    for r in results:
        diff = r['difficulty']
        stats[diff] = stats.get(diff, 0) + 1
    
    print("\n" + "="*50)
    print("éš¾åº¦ç»Ÿè®¡:")
    print("="*50)
    total = len(results)
    for diff in ['easy', 'medium', 'hard', 'extra', 'error']:
        if diff in stats:
            count = stats[diff]
            percentage = (count / total) * 100
            print(f"{diff:10s}: {count:4d} ({percentage:5.1f}%)")
    print("="*50)
    print(f"æ€»è®¡: {total} (æˆåŠŸ: {success_count}, å¤±è´¥: {error_count})")
    
    return results

# if __name__ == "__main__":
#     import argparse
#     GOLD_PATH = 'D:/project/dsaa6000R/spider-master/spider_data/test_gold.sql'
#     DB_PATH = 'D:/project/dsaa6000R/spider-master/spider_data/test_database'
#     SCHEMA_PATH = 'D:/project/dsaa6000R/spider-master/spider_data/test_tables.json'
    
#     parser = argparse.ArgumentParser(description='ä¸ºSpideræ•°æ®é›†çš„gold SQLæ ‡æ³¨éš¾åº¦')
#     parser.add_argument('--gold', default=GOLD_PATH, help='gold SQLæ–‡ä»¶è·¯å¾„')
#     parser.add_argument('--db', default=DB_PATH, help='æ•°æ®åº“ç›®å½•')
#     parser.add_argument('--table', default=SCHEMA_PATH, help='tables.jsonæ–‡ä»¶è·¯å¾„')
#     parser.add_argument('--output', default='gold_with_difficulty.json', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    
#     args = parser.parse_args()
    
#     # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
#     for path, name in [(args.gold, 'Goldæ–‡ä»¶'), (args.table, 'Tablesæ–‡ä»¶'), (args.db, 'æ•°æ®åº“ç›®å½•')]:
#         if not os.path.exists(path):
#             print(f"âŒ æ‰¾ä¸åˆ°{name}: {path}")
#             sys.exit(1)
    
#     print("="*50)
#     print("å¼€å§‹å¤„ç†...")
#     print("="*50)
#     print(f"Goldæ–‡ä»¶: {args.gold}")
#     print(f"æ•°æ®åº“ç›®å½•: {args.db}")
#     print(f"Tablesæ–‡ä»¶: {args.table}")
#     print(f"è¾“å‡ºæ–‡ä»¶: {args.output}")
#     print("="*50 + "\n")
    
#     results = label_difficulty(args.gold, args.db, args.table, args.output)
    
#     print(f"\nâœ… å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: {args.output}")



